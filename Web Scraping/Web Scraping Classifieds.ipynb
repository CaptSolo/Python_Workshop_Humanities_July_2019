{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we did no have requests then we would install it manually:\n",
    "# !pip install requests from Jupyter notebook\n",
    "# pip install requests from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ss.com/lv/real-estate/wood/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url)\n",
    "req.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.content[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lxml parser is an optional parser which is supposed to work better than built in Python html parser\n",
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(soup.body.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.a.contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.a.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.a.attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.a.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.a.img.attrs['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all anchor tags (those with <a .... >)\n",
    "allanchors = soup.find_all('a')\n",
    "len(allanchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someanch = allanchors[20]\n",
    "someanch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someanch.attrs['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someanch['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someanch['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find all anchor tags with a specific class ('a_category') here\n",
    "anchorlist = soup.find_all('a', {'class': 'a_category'})\n",
    "len(anchorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a list of web addresses(urls) using a list comprehension\n",
    "urlist = [el['href'] for el in anchorlist]\n",
    "len(urlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda is an anonymous function\n",
    "myadder = lambda a,b:a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myadder(6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe if we need a fuzzy search through an id attribute\n",
    "# we need to check if id attribute exists and only then check for the value\n",
    "ahclist = soup.find_all(lambda el: 'id' in el.attrs and 'ahc' in el.attrs['id'])\n",
    "len(ahclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahclist[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = soup.find_all(lambda el: 'class' in el.attrs and el.attrs['class'] == 'a_category')\n",
    "len(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = soup.find_all(lambda el: 'class' in el.attrs and 'a_category' in el.attrs['class'])\n",
    "len(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = soup.find_all(lambda el: len(el.attrs) > 3)\n",
    "len(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist[0]['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = soup.find_all(lambda el: 'class' in el and el['class'] == 'a_category')\n",
    "len(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytags = soup.find_all()\n",
    "len(mytags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytags[30].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allid = soup.find_all(lambda el: 'id' in el.attrs)\n",
    "len(allid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantags=[]\n",
    "mytags = soup.find_all()\n",
    "for tag in mytags:\n",
    "    if 'id' in tag.attrs:\n",
    "        cleantags.append(tag)\n",
    "len(cleantags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctags=[]\n",
    "mytags = soup.find_all()\n",
    "for tag in mytags:\n",
    "    if 'id' in tag.attrs and 'ahc' in tag.attrs['id']:\n",
    "        ahctags.append(tag)\n",
    "len(ahctags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://www.ss.com\"\n",
    "postfix = \"sell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullurls = [baseurl + el + postfix for el in urlist]\n",
    "fullurls[:3]\n",
    "#could write loop go through urlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullurls = []\n",
    "#could write loop go through urlist\n",
    "for el in urlist:\n",
    "    fullurls.append(baseurl + el + postfix)\n",
    "fullurls[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furlist = [baseurl + el for el in urlist]\n",
    "furlist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix = 'sell/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellist = [el+postfix for el in furlist]\n",
    "sellist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftables = pd.read_html(sellist[0])\n",
    "len(dftables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riga = dftables[8]\n",
    "riga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(riga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigaurl = sellist[0]\n",
    "rigaurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRows(url):\n",
    "    req = requests.get(url)\n",
    "    rows = []\n",
    "    if req.status_code != 200:\n",
    "        print(\"Bad Request\"+req.status_code)\n",
    "        return\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    print(\"Processing: \"+ str(soup.title))\n",
    "    alltrs = rsoup.find_all('tr')\n",
    "    for el in alltrs:\n",
    "        if 'id' in el.attrs and 'tr_' in el.attrs['id']:\n",
    "            rows.append(el)\n",
    "    rows.pop() # we do not need the last one nor do we need to store\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aizkraukle = getRows(sellist[1])\n",
    "aizkraukle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreq = requests.get(rigaurl)\n",
    "rreq.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsoup = BeautifulSoup(rreq.text, 'lxml')\n",
    "rsoup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranchors = rsoup.find_all('a', class_ = 'am')\n",
    "len(ranchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltrs = rsoup.find_all('tr')\n",
    "len(alltrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrows = []\n",
    "for el in alltrs:\n",
    "    if 'id' in el.attrs and 'tr_' in el.attrs['id']:\n",
    "        myrows.append(el)\n",
    "len(myrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrows[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need the last one so we just throw away the last one\n",
    "myrows = myrows[:-1]\n",
    "len(myrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first row\n",
    "row1 = myrows[0]\n",
    "row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all data cells for first row\n",
    "tds = row1.find_all('td')\n",
    "len(tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[1].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[1].a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[1].a['badattribute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean some text\n",
    "tds[2].text.strip().replace('\\r','').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[5].text.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = int(tds[5].text.split()[0].replace(',',''))\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds[5].text.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRow(row, baseurl='https://www.ss.com'):\n",
    "    ritems = []\n",
    "    tds = row.find_all('td')\n",
    "    ritems.append(baseurl + tds[1].a['href'])\n",
    "    ritems.append(tds[2].text.strip().replace('\\r','').replace('\\n', ''))\n",
    "    for td in tds[3:-1]:\n",
    "        ritems.append(td.text)\n",
    "    ritems.append(int(tds[-1].text.split()[0].replace(',','')))\n",
    "    ritems.append(tds[-1].text.split()[1])\n",
    "    return ritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrow = processRow(myrows[0])\n",
    "myrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRows(rows):\n",
    "    rowlist=[]\n",
    "    for row in rows:\n",
    "        rowlist.append(processRow(row))\n",
    "    return rowlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRows(url):\n",
    "    req = requests.get(url)\n",
    "    rows = []\n",
    "    if req.status_code != 200:\n",
    "        print(\"Bad Request\"+req.status_code)\n",
    "        return\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    print(\"Processing: \"+ str(soup.title))\n",
    "    # this will be specific to ss.lv and ss.com\n",
    "    alltrs = soup.find_all('tr')\n",
    "    for el in alltrs:\n",
    "        if 'id' in el.attrs and 'tr_' in el.attrs['id']:\n",
    "            rows.append(el)\n",
    "    rows.pop() # we do not need the last one nor do we need to store\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPage(url):\n",
    "    rows = getRows(url)\n",
    "    mylist = processRows(rows)\n",
    "    return mylist # could return processRows(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPages(urls):\n",
    "    results = []\n",
    "    for url in urls:\n",
    "        print(\"Processing: \"+url)\n",
    "        results += processPage(url)\n",
    "        time.sleep(0.1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist2 = processPages(sellist)\n",
    "len(mlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = processPages(sellist)\n",
    "len(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['URL','Desc','Region','Area','Price','Currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mylist)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + can concatanate only same type elements so list with list\n",
    "# so we need to make a single element such as index[0] into a list of one element such as [index[0]]\n",
    "\n",
    "df2 = df[columns[1:]+[columns[0]]]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + can concatanate only same type elements so list with list\n",
    "# so we need to make a single element such as index[0] into a list of one element such as [index[0]]\n",
    "\n",
    "df2 = df[index[1:]+[index[0]]]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aizlist = processPage(sellist[1])\n",
    "aizlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(aizlist)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(myrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedrows = processPage(myrows)\n",
    "cleanedrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPages(pages):\n",
    "    mylist=[]\n",
    "    for page in pages:\n",
    "        mylist += "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranchors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rurls= [baseurl+el['href'] for el in ranchors]\n",
    "rurls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrlList(url, prefix='https://www.ss.com', postfix='sell/', tag='a', class_='a_category'):\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(f'Unexpected status code {req.status_code}. Stopping parse')\n",
    "        return [] #return early and often principle\n",
    "    soup = BeautifulSoup(req.text, 'lxml') # could skip soup variable as well but keeping for readability\n",
    "    return [ prefix + el['href'] + postfix for el in soup.find_all(tag, class_) ]\n",
    "    # What else could we pass as argument? How could our return fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = getUrlList(\"https://www.ss.com/lv/real-estate/flats/\")\n",
    "len(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlist=getUrlList('https://www.ss.com/lv/real-estate/flats/riga-region/sell/', postfix='')\n",
    "rlist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processPage(rlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreq = requests.get(rurl)\n",
    "rreq.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsoup = BeautifulSoup(rreq.text, 'lxml')\n",
    "rsoup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtables = rsoup.find_all('table')\n",
    "len(rtables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrows = rsoup.find_all('tr',id = re.compile(r'tr_*')) #basic wildcard search could use tr_ in lambda function\n",
    "len(rrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = rsoup.find('tr', id = \"head_line\")\n",
    "print(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cindex = [el.text for el in headline.find_all('td')]\n",
    "cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cindex[0].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cindex[0] = cindex[0].split()[0]\n",
    "cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cindex += ['URL']  #vai cindex.append('URL')\n",
    "cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowData(row):\n",
    "    return [el.text for el in row.find_all('td')[2:]] + [baseurl + row.find('a')['href']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowdata = getRowData(rrows[0])\n",
    "rowdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsdata = [getRowData(el) for el in rrows] # It should work but what there is a hidden last element :)\n",
    "rowsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsdata = [getRowData(el) for el in rrows[:-1]] # so we just skip the last element\n",
    "rowsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rowsdata, columns=cindex)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf = pd.concat([df,df])\n",
    "bigdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFfromUrl(url):\n",
    "    print(f'Going gather data from URL:{url}')\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(f'Unexpected status code {req.status_code}. Stopping parse')\n",
    "        return [] #return early and often principle\n",
    "    soup = BeautifulSoup(req.text, 'lxml') # could skip soup variable as well but keeping for readability\n",
    "    headline = soup.find('tr', id = \"head_line\")\n",
    "    cindex = [el.text for el in headline.find_all('td')]\n",
    "    cindex[0] = cindex[0].split()[0]\n",
    "    cindex += ['URL'] #TODO add argument for this\n",
    "    rows = soup.find_all('tr',id = re.compile(r'tr_*'))\n",
    "    rowsdata = [getRowData(el) for el in rows[:-1]]\n",
    "    return pd.DataFrame(rowsdata, columns=cindex)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = getDFfromUrl(woodlist[12])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFfromUrlList(urlist):\n",
    "    dflist = []\n",
    "    for ur in urlist:\n",
    "        dflist.append(getDFfromUrl(ur))\n",
    "    return pd.concat(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdf = getDFfromUrlList(woodlist)\n",
    "bigdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/10607688/how-to-create-a-file-name-with-the-current-date-time-in-python\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html\n",
    "# Let's use with context manager so we do not forget to close writer!\n",
    "with pd.ExcelWriter(f'sellers_{timestr}.xlsx') as writer:\n",
    "    bigdf.to_excel(writer, sheet_name='Sheet_name_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
