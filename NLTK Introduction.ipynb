{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit (NLTK)\n",
    "\n",
    "**NLTK** is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to [over 50 corpora and lexical resources](http://www.nltk.org/nltk_data/) such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "\n",
    "http://www.nltk.org/\n",
    "\n",
    "NLTK library documentation (reference) = *Use it to look up how to use a particular NLTK library function*\n",
    "* https://www.nltk.org/api/nltk.html\n",
    "\n",
    "---\n",
    "\n",
    "NLTK wiki (collaboratively edited documentation):\n",
    "* https://github.com/nltk/nltk/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book: Natural Language Processing with Python \n",
    "\n",
    "NLTK book provides a practical introduction to programming for language processing.\n",
    "\n",
    "Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more.\n",
    "\n",
    "Online: http://www.nltk.org/book/\n",
    "\n",
    "* we will start with Chapter 1: [\"Language Processing and Python\"](http://www.nltk.org/book/ch01.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for the notebook \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Getting started\n",
    "\n",
    "NLTK book: http://www.nltk.org/book/ch01.html#getting-started-with-nltk\n",
    "\n",
    "* Loading NLTK (Python module)\n",
    "* Downloading NLTK language resources (corpora, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use a Python library, we need to import (load) it\n",
    "\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ntlk.Text` is a simple NLTK helper for loading and exploring textual content (a sequence of words / string tokens):**\n",
    "\n",
    "... intended to support initial exploration of texts (via the interactive console). Its methods perform a variety of analyses on the textâ€™s contexts (e.g., counting, concordancing, collocation discovery), and display the results.\n",
    "\n",
    "Documentation: [nltk.Text](https://www.nltk.org/api/nltk.html#nltk.text.Text)\n",
    "* lists what we can do with text once it is loaded into nltk.Text(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: This is just an example Another example here...>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can try a simple example:\n",
    "\n",
    "my_word_list = [\"This\", \"is\", \"just\", \"an\", \"example\", \"Another\", \"example\", \"here\"]\n",
    "my_text = nltk.Text(my_word_list)\n",
    "\n",
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# How many times does the word \"example\" appear?\n",
    "print(my_text.count(\"example\"))\n",
    "\n",
    "# Notes:\n",
    "#  - my_text = our text, processed (loaded) by NLTK\n",
    "#     - technically: a Python object\n",
    "#  - my_text.count(...) = requesting the object to perform a .count(...) function and return the result\n",
    "#     - technically: calling a .count() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading NLTK language resources\n",
    "\n",
    "NLTK also contains many language resources (corpora, ...) but you have select and download them separately (in order to save disk space and only download what is needed).\n",
    "\n",
    "Let's download text collections used in the NLTK book: \n",
    "* `nltk.download(\"book\")`\n",
    "\n",
    "Note: you can also download resources interactively:\n",
    "* `nltk.download()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/captsolo/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# After downloading the reources we still need to import them\n",
    "\n",
    "# Let's import all NLTK book resource (*)\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Exploring textual content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text1, ... resources are of type nltk.Text (same as in the earlier example):\n",
    "\n",
    "type(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    }
   ],
   "source": [
    "# We can run all methods that nltk.Text has.\n",
    "\n",
    "# Count words:\n",
    "print(text1.count(\"whale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "cean , in order , if possible , to discover a passage through it to India , th\n",
      " throw at the whales , in order to discover when they were nigh enough to risk\n",
      "for ever reach new distances , and discover sights more sweet and strange than\n",
      "gs upon the plain , you will often discover images as of the petrified forms o\n",
      " over numberless unknown worlds to discover his one superficial western one ; \n",
      "se two heads for hours , and never discover that organ . The ear has no extern\n",
      "s keener than man ' s ; Ahab could discover no sign in the sea . But suddenly \n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.concordance\n",
    "\n",
    "# Print concordance view (occurences of a word, in context):\n",
    "text1.concordance(\"discover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 316 matches:\n",
      " to the character of an independent nation seems to have been distinguished by\n",
      "f Heaven can never be expected on a nation that disregards the eternal rules o\n",
      "first , the representatives of this nation , then consisting of little more th\n",
      ", situation , and relations of this nation and country than any which had ever\n",
      ", prosperity , and happiness of the nation I have acquired an habitual attachm\n",
      "an be no spectacle presented by any nation more pleasing , more noble , majest\n",
      "party for its own ends , not of the nation for the national good . If that sol\n",
      "tures and the people throughout the nation . On this subject it might become m\n",
      "if a personal esteem for the French nation , formed in a residence of seven ye\n",
      "f our fellow - citizens by whatever nation , and if success can not be obtaine\n",
      "y , continue His blessing upon this nation and its Government and give it all \n",
      "powers so justly inspire . A rising nation , spread over a wide and fruitful l\n",
      "ing now decided by the voice of the nation , announced according to the rules \n",
      "ars witness to the fact that a just nation is trusted on its word when recours\n",
      "e union of opinion which gives to a nation the blessing of harmony and the ben\n",
      "uil suffrage of a free and virtuous nation , would under any circumstances hav\n",
      "d spirit and united councils of the nation will be safeguards to its honor and\n",
      "iction that the war with a powerful nation , which forms so prominent a featur\n",
      "out breaking down the spirit of the nation , destroying all confidence in itse\n",
      "ed on the military resources of the nation . These resources are amply suffici\n",
      "the war to an honorable issue . Our nation is in number more than half that of\n",
      "ndividually have been happy and the nation prosperous . Under this Constitutio\n",
      "rights , and is able to protect the nation against injustice from foreign powe\n",
      " great agricultural interest of the nation prospers under its protection . Loc\n",
      "ak our Union , and demolish us as a nation . Our distance from Europe and the \n"
     ]
    }
   ],
   "source": [
    "text4.concordance(\"nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country people government world union time constitution states\n",
      "republic land law party earth other future president war executive\n",
      "congress peace\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.similar\n",
    "\n",
    "# Print words that appear in similar context as \"nation\".\n",
    "text4.similar(\"nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that_, a_, every_, by_or that_; of_; the_previous by_, -_, of_. the_,\n",
      "one_, all_. the_. this_in all_in the_before after_, the_wore\n",
      "through_into\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.common_contexts\n",
    "\n",
    "# Find contexts common to all given words\n",
    "text1.common_contexts([\"day\", \"night\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Python lists\n",
    "\n",
    "A *list* contains multiple values in an ordered sequence.\n",
    "\n",
    "More about Python lists:\n",
    "* https://automatetheboringstuff.com/chapter4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# nltk.Text is also a list - can do everything we can do with lists (access parts of it, ...)\n",
    "\n",
    "# What's the 1st occurence of \"He\" in the text?\n",
    "#  - note: Python is case sensitive (unless you take care of it - e.g. convert all text to lowercase)\n",
    "\n",
    "print(text1.index(\"He\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n"
     ]
    }
   ],
   "source": [
    "# The word at position #42\n",
    "#  - note: list indexes start from 0\n",
    "\n",
    "print(text1[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', ',']\n"
     ]
    }
   ],
   "source": [
    "print(text1[42:52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further exploration\n",
    "\n",
    "* Dispersion plots (distribution of words throughout the text)\n",
    "* Generating text (based on example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is it stripped off from some mountain torrent we had flip ? , so as to\n",
      "preserve all his might had in former years abounding with them , they\n",
      "toil with their lances , strange tales of Southern whaling .\n",
      "conceivable that this fine old Dutch Fishery , a most wealthy example\n",
      "of the sea - captain orders me to admire the magnanimity of the whole\n",
      ", and many whalemen , but dumplings ; good white cedar of the ship\n",
      "casts off her cables ; and chewed it noiselessly ; and though there\n",
      "are birds called grey albatrosses ; and yet faster\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why is it stripped off from some mountain torrent we had flip ? , so as to\\npreserve all his might had in former years abounding with them , they\\ntoil with their lances , strange tales of Southern whaling .\\nconceivable that this fine old Dutch Fishery , a most wealthy example\\nof the sea - captain orders me to admire the magnanimity of the whole\\n, and many whalemen , but dumplings ; good white cedar of the ship\\ncasts off her cables ; and chewed it noiselessly ; and though there\\nare birds called grey albatrosses ; and yet faster'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate text (based on example)\n",
    "# https://www.nltk.org/api/nltk.html#nltk.text.Text.generate\n",
    "\n",
    "text1.generate(text_seed=[\"Why\", \"is\", \"it\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.lm in nltk:\n",
      "\n",
      "NAME\n",
      "    nltk.lm\n",
      "\n",
      "DESCRIPTION\n",
      "    NLTK Language Modeling Module.\n",
      "    ------------------------------\n",
      "    \n",
      "    Currently this module covers only ngram language models, but it should be easy\n",
      "    to extend to neural models.\n",
      "    \n",
      "    \n",
      "    Preparing Data\n",
      "    ==============\n",
      "    \n",
      "    Before we train our ngram models it is necessary to make sure the data we put in\n",
      "    them is in the right format.\n",
      "    Let's say we have a text that is a list of sentences, where each sentence is\n",
      "    a list of strings. For simplicity we just consider a text consisting of\n",
      "    characters instead of words.\n",
      "    \n",
      "        >>> text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
      "    \n",
      "    If we want to train a bigram model, we need to turn this text into bigrams.\n",
      "    Here's what the first sentence of our text would look like if we use a function\n",
      "    from NLTK for this.\n",
      "    \n",
      "        >>> from nltk.util import bigrams\n",
      "        >>> list(bigrams(text[0]))\n",
      "        [('a', 'b'), ('b', 'c')]\n",
      "    \n",
      "    Notice how \"b\" occurs both as the first and second member of different bigrams\n",
      "    but \"a\" and \"c\" don't? Wouldn't it be nice to somehow indicate how often sentences\n",
      "    start with \"a\" and end with \"c\"?\n",
      "    A standard way to deal with this is to add special \"padding\" symbols to the\n",
      "    sentence before splitting it into ngrams.\n",
      "    Fortunately, NLTK also has a function for that, let's see what it does to the\n",
      "    first sentence.\n",
      "    \n",
      "        >>> from nltk.util import pad_sequence\n",
      "        >>> list(pad_sequence(text[0],\n",
      "        ... pad_left=True,\n",
      "        ... left_pad_symbol=\"<s>\",\n",
      "        ... pad_right=True,\n",
      "        ... right_pad_symbol=\"</s>\",\n",
      "        ... n=2))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>']\n",
      "    \n",
      "    Note the `n` argument, that tells the function we need padding for bigrams.\n",
      "    Now, passing all these parameters every time is tedious and in most cases they\n",
      "    can be safely assumed as defaults anyway.\n",
      "    Thus our module provides a convenience function that has all these arguments\n",
      "    already set while the other arguments remain the same as for `pad_sequence`.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import pad_both_ends\n",
      "        >>> list(pad_both_ends(text[0], n=2))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>']\n",
      "    \n",
      "    Combining the two parts discussed so far we get the following preparation steps\n",
      "    for one sentence.\n",
      "    \n",
      "        >>> list(bigrams(pad_both_ends(text[0], n=2)))\n",
      "        [('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]\n",
      "    \n",
      "    To make our model more robust we could also train it on unigrams (single words)\n",
      "    as well as bigrams, its main source of information.\n",
      "    NLTK once again helpfully provides a function called `everygrams`.\n",
      "    While not the most efficient, it is conceptually simple.\n",
      "    \n",
      "    \n",
      "        >>> from nltk.util import everygrams\n",
      "        >>> padded_bigrams = list(pad_both_ends(text[0], n=2))\n",
      "        >>> list(everygrams(padded_bigrams, max_len=2))\n",
      "        [('<s>',),\n",
      "         ('a',),\n",
      "         ('b',),\n",
      "         ('c',),\n",
      "         ('</s>',),\n",
      "         ('<s>', 'a'),\n",
      "         ('a', 'b'),\n",
      "         ('b', 'c'),\n",
      "         ('c', '</s>')]\n",
      "    \n",
      "    We are almost ready to start counting ngrams, just one more step left.\n",
      "    During training and evaluation our model will rely on a vocabulary that\n",
      "    defines which words are \"known\" to the model.\n",
      "    To create this vocabulary we need to pad our sentences (just like for counting\n",
      "    ngrams) and then combine the sentences into one flat stream of words.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import flatten\n",
      "        >>> list(flatten(pad_both_ends(sent, n=2) for sent in text))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']\n",
      "    \n",
      "    In most cases we want to use the same text as the source for both vocabulary\n",
      "    and ngram counts.\n",
      "    Now that we understand what this means for our preprocessing, we can simply import\n",
      "    a function that does everything for us.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import padded_everygram_pipeline\n",
      "        >>> train, vocab = padded_everygram_pipeline(2, text)\n",
      "    \n",
      "    So as to avoid re-creating the text in memory, both `train` and `vocab` are lazy\n",
      "    iterators. They are evaluated on demand at training time.\n",
      "    \n",
      "    \n",
      "    Training\n",
      "    ========\n",
      "    Having prepared our data we are ready to start training a model.\n",
      "    As a simple example, let us train a Maximum Likelihood Estimator (MLE).\n",
      "    We only need to specify the highest ngram order to instantiate it.\n",
      "    \n",
      "        >>> from nltk.lm import MLE\n",
      "        >>> lm = MLE(2)\n",
      "    \n",
      "    This automatically creates an empty vocabulary...\n",
      "    \n",
      "        >>> len(lm.vocab)\n",
      "        0\n",
      "    \n",
      "    ... which gets filled as we fit the model.\n",
      "    \n",
      "        >>> lm.fit(train, vocab)\n",
      "        >>> print(lm.vocab)\n",
      "        <Vocabulary with cutoff=1 unk_label='<UNK>' and 9 items>\n",
      "        >>> len(lm.vocab)\n",
      "        9\n",
      "    \n",
      "    The vocabulary helps us handle words that have not occurred during training.\n",
      "    \n",
      "        >>> lm.vocab.lookup(text[0])\n",
      "        ('a', 'b', 'c')\n",
      "        >>> lm.vocab.lookup([\"aliens\", \"from\", \"Mars\"])\n",
      "        ('<UNK>', '<UNK>', '<UNK>')\n",
      "    \n",
      "    Moreover, in some cases we want to ignore words that we did see during training\n",
      "    but that didn't occur frequently enough, to provide us useful information.\n",
      "    You can tell the vocabulary to ignore such words.\n",
      "    To find out how that works, check out the docs for the `Vocabulary` class.\n",
      "    \n",
      "    \n",
      "    Using a Trained Model\n",
      "    =====================\n",
      "    When it comes to ngram models the training boils down to counting up the ngrams\n",
      "    from the training corpus.\n",
      "    \n",
      "        >>> print(lm.counts)\n",
      "        <NgramCounter with 2 ngram orders and 24 ngrams>\n",
      "    \n",
      "    This provides a convenient interface to access counts for unigrams...\n",
      "    \n",
      "        >>> lm.counts['a']\n",
      "        2\n",
      "    \n",
      "    ...and bigrams (in this case \"a b\")\n",
      "    \n",
      "        >>> lm.counts[['a']]['b']\n",
      "        1\n",
      "    \n",
      "    And so on. However, the real purpose of training a language model is to have it\n",
      "    score how probable words are in certain contexts.\n",
      "    This being MLE, the model returns the item's relative frequency as its score.\n",
      "    \n",
      "        >>> lm.score(\"a\")\n",
      "        0.15384615384615385\n",
      "    \n",
      "    Items that are not seen during training are mapped to the vocabulary's\n",
      "    \"unknown label\" token. This is \"<UNK>\" by default.\n",
      "    \n",
      "        >>> lm.score(\"<UNK>\") == lm.score(\"aliens\")\n",
      "        True\n",
      "    \n",
      "    Here's how you get the score for a word given some preceding context.\n",
      "    For example we want to know what is the chance that \"b\" is preceded by \"a\".\n",
      "    \n",
      "        >>> lm.score(\"b\", [\"a\"])\n",
      "        0.5\n",
      "    \n",
      "    To avoid underflow when working with many small score values it makes sense to\n",
      "    take their logarithm.\n",
      "    For convenience this can be done with the `logscore` method.\n",
      "    \n",
      "        >>> lm.logscore(\"a\")\n",
      "        -2.700439718141092\n",
      "    \n",
      "    Building on this method, we can also evaluate our model's cross-entropy and\n",
      "    perplexity with respect to sequences of ngrams.\n",
      "    \n",
      "        >>> test = [('a', 'b'), ('c', 'd')]\n",
      "        >>> lm.entropy(test)\n",
      "        1.292481250360578\n",
      "        >>> lm.perplexity(test)\n",
      "        2.449489742783178\n",
      "    \n",
      "    It is advisable to preprocess your test text exactly the same way as you did\n",
      "    the training text.\n",
      "    \n",
      "    One cool feature of ngram models is that they can be used to generate text.\n",
      "    \n",
      "        >>> lm.generate(1, random_seed=3)\n",
      "        '<s>'\n",
      "        >>> lm.generate(5, random_seed=3)\n",
      "        ['<s>', 'a', 'b', 'c', 'd']\n",
      "    \n",
      "    Provide `random_seed` if you want to consistently reproduce the same text all\n",
      "    other things being equal. Here we are using it to test the examples.\n",
      "    \n",
      "    You can also condition your generation on some preceding text with the `context`\n",
      "    argument.\n",
      "    \n",
      "        >>> lm.generate(5, text_seed=['c'], random_seed=3)\n",
      "        ['</s>', 'c', 'd', 'c', 'd']\n",
      "    \n",
      "    Note that an ngram model is restricted in how much preceding context it can\n",
      "    take into account. For example, a trigram model can only condition its output\n",
      "    on 2 preceding words. If you pass in a 4-word context, the first two words\n",
      "    will be ignored.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    counter\n",
      "    models\n",
      "    preprocessing\n",
      "    smoothing\n",
      "    util\n",
      "    vocabulary\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        nltk.lm.counter.NgramCounter\n",
      "        nltk.lm.vocabulary.Vocabulary\n",
      "    nltk.lm.api.LanguageModel(builtins.object)\n",
      "        nltk.lm.models.Lidstone\n",
      "            nltk.lm.models.Laplace\n",
      "        nltk.lm.models.MLE\n",
      "    nltk.lm.models.InterpolatedLanguageModel(nltk.lm.api.LanguageModel)\n",
      "        nltk.lm.models.KneserNeyInterpolated\n",
      "        nltk.lm.models.WittenBellInterpolated\n",
      "    \n",
      "    class KneserNeyInterpolated(InterpolatedLanguageModel)\n",
      "     |  KneserNeyInterpolated(order, discount=0.1, **kwargs)\n",
      "     |  \n",
      "     |  Interpolated version of Kneser-Ney smoothing.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KneserNeyInterpolated\n",
      "     |      InterpolatedLanguageModel\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, order, discount=0.1, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from InterpolatedLanguageModel:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Score a word given some optional context.\n",
      "     |      \n",
      "     |      Concrete models are expected to provide an implementation.\n",
      "     |      Note that this method does not mask its arguments with the OOV label.\n",
      "     |      Use the `score` method for that.\n",
      "     |      \n",
      "     |      :param str word: Word for which we want the score\n",
      "     |      :param tuple(str) context: Context the word is in.\n",
      "     |      If `None`, compute unigram score.\n",
      "     |      :param context: tuple(str) or None\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Laplace(Lidstone)\n",
      "     |  Laplace(*args, **kwargs)\n",
      "     |  \n",
      "     |  Implements Laplace (add one) smoothing.\n",
      "     |  \n",
      "     |  Initialization identical to BaseNgramModel because gamma is always 1.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Laplace\n",
      "     |      Lidstone\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lidstone:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Add-one smoothing: Lidstone or Laplace.\n",
      "     |      \n",
      "     |      To see what kind, look at `gamma` attribute on the class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Lidstone(nltk.lm.api.LanguageModel)\n",
      "     |  Lidstone(gamma, *args, **kwargs)\n",
      "     |  \n",
      "     |  Provides Lidstone-smoothed scores.\n",
      "     |  \n",
      "     |  In addition to initialization arguments from BaseNgramModel also requires\n",
      "     |  a number by which to increase the counts, gamma.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Lidstone\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, gamma, *args, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Add-one smoothing: Lidstone or Laplace.\n",
      "     |      \n",
      "     |      To see what kind, look at `gamma` attribute on the class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MLE(nltk.lm.api.LanguageModel)\n",
      "     |  MLE(order, vocabulary=None, counter=None)\n",
      "     |  \n",
      "     |  Class for providing MLE ngram model scores.\n",
      "     |  \n",
      "     |  Inherits initialization from BaseNgramModel.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MLE\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Returns the MLE score for a word given a context.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |      - word is expcected to be a string\n",
      "     |      - context is expected to be something reasonably convertible to a tuple\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __init__(self, order, vocabulary=None, counter=None)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NgramCounter(builtins.object)\n",
      "     |  NgramCounter(ngram_text=None)\n",
      "     |  \n",
      "     |  Class for counting ngrams.\n",
      "     |  \n",
      "     |  Will count any ngram sequence you give it ;)\n",
      "     |  \n",
      "     |  First we need to make sure we are feeding the counter sentences of ngrams.\n",
      "     |  \n",
      "     |  >>> text = [[\"a\", \"b\", \"c\", \"d\"], [\"a\", \"c\", \"d\", \"c\"]]\n",
      "     |  >>> from nltk.util import ngrams\n",
      "     |  >>> text_bigrams = [ngrams(sent, 2) for sent in text]\n",
      "     |  >>> text_unigrams = [ngrams(sent, 1) for sent in text]\n",
      "     |  \n",
      "     |  The counting itself is very simple.\n",
      "     |  \n",
      "     |  >>> from nltk.lm import NgramCounter\n",
      "     |  >>> ngram_counts = NgramCounter(text_bigrams + text_unigrams)\n",
      "     |  \n",
      "     |  You can conveniently access ngram counts using standard python dictionary notation.\n",
      "     |  String keys will give you unigram counts.\n",
      "     |  \n",
      "     |  >>> ngram_counts['a']\n",
      "     |  2\n",
      "     |  >>> ngram_counts['aliens']\n",
      "     |  0\n",
      "     |  \n",
      "     |  If you want to access counts for higher order ngrams, use a list or a tuple.\n",
      "     |  These are treated as \"context\" keys, so what you get is a frequency distribution\n",
      "     |  over all continuations after the given context.\n",
      "     |  \n",
      "     |  >>> sorted(ngram_counts[['a']].items())\n",
      "     |  [('b', 1), ('c', 1)]\n",
      "     |  >>> sorted(ngram_counts[('a',)].items())\n",
      "     |  [('b', 1), ('c', 1)]\n",
      "     |  \n",
      "     |  This is equivalent to specifying explicitly the order of the ngram (in this case\n",
      "     |  2 for bigram) and indexing on the context.\n",
      "     |  >>> ngram_counts[2][('a',)] is ngram_counts[['a']]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Note that the keys in `ConditionalFreqDist` cannot be lists, only tuples!\n",
      "     |  It is generally advisable to use the less verbose and more flexible square\n",
      "     |  bracket notation.\n",
      "     |  \n",
      "     |  To get the count of the full ngram \"a b\", do this:\n",
      "     |  \n",
      "     |  >>> ngram_counts[['a']]['b']\n",
      "     |  1\n",
      "     |  \n",
      "     |  Specifying the ngram order as a number can be useful for accessing all ngrams\n",
      "     |  in that order.\n",
      "     |  \n",
      "     |  >>> ngram_counts[2]\n",
      "     |  <ConditionalFreqDist with 4 conditions>\n",
      "     |  \n",
      "     |  The keys of this `ConditionalFreqDist` are the contexts we discussed earlier.\n",
      "     |  Unigrams can also be accessed with a human-friendly alias.\n",
      "     |  \n",
      "     |  >>> ngram_counts.unigrams is ngram_counts[1]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Similarly to `collections.Counter`, you can update counts after initialization.\n",
      "     |  \n",
      "     |  >>> ngram_counts['e']\n",
      "     |  0\n",
      "     |  >>> ngram_counts.update([ngrams([\"d\", \"e\", \"f\"], 1)])\n",
      "     |  >>> ngram_counts['e']\n",
      "     |  1\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  N(self)\n",
      "     |      Returns grand total number of ngrams stored.\n",
      "     |      \n",
      "     |      This includes ngrams from all orders, so some duplication is expected.\n",
      "     |      :rtype: int\n",
      "     |      \n",
      "     |      >>> from nltk.lm import NgramCounter\n",
      "     |      >>> counts = NgramCounter([[(\"a\", \"b\"), (\"c\",), (\"d\", \"e\")]])\n",
      "     |      >>> counts.N()\n",
      "     |      3\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |      User-friendly access to ngram counts.\n",
      "     |  \n",
      "     |  __init__(self, ngram_text=None)\n",
      "     |      Creates a new NgramCounter.\n",
      "     |      \n",
      "     |      If `ngram_text` is specified, counts ngrams from it, otherwise waits for\n",
      "     |      `update` method to be called explicitly.\n",
      "     |      \n",
      "     |      :param ngram_text: Optional text containing senteces of ngrams, as for `update` method.\n",
      "     |      :type ngram_text: Iterable(Iterable(tuple(str))) or None\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  update(self, ngram_text)\n",
      "     |      Updates ngram counts from `ngram_text`.\n",
      "     |      \n",
      "     |      Expects `ngram_text` to be a sequence of sentences (sequences).\n",
      "     |      Each sentence consists of ngrams as tuples of strings.\n",
      "     |      \n",
      "     |      :param Iterable(Iterable(tuple(str))) ngram_text: Text containing senteces of ngrams.\n",
      "     |      :raises TypeError: if the ngrams are not tuples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Vocabulary(builtins.object)\n",
      "     |  Vocabulary(counts=None, unk_cutoff=1, unk_label='<UNK>')\n",
      "     |  \n",
      "     |  Stores language model vocabulary.\n",
      "     |  \n",
      "     |  Satisfies two common language modeling requirements for a vocabulary:\n",
      "     |  - When checking membership and calculating its size, filters items\n",
      "     |    by comparing their counts to a cutoff value.\n",
      "     |  - Adds a special \"unknown\" token which unseen words are mapped to.\n",
      "     |  \n",
      "     |  >>> words = ['a', 'c', '-', 'd', 'c', 'a', 'b', 'r', 'a', 'c', 'd']\n",
      "     |  >>> from nltk.lm import Vocabulary\n",
      "     |  >>> vocab = Vocabulary(words, unk_cutoff=2)\n",
      "     |  \n",
      "     |  Tokens with counts greater than or equal to the cutoff value will\n",
      "     |  be considered part of the vocabulary.\n",
      "     |  \n",
      "     |  >>> vocab['c']\n",
      "     |  3\n",
      "     |  >>> 'c' in vocab\n",
      "     |  True\n",
      "     |  >>> vocab['d']\n",
      "     |  2\n",
      "     |  >>> 'd' in vocab\n",
      "     |  True\n",
      "     |  \n",
      "     |  Tokens with frequency counts less than the cutoff value will be considered not\n",
      "     |  part of the vocabulary even though their entries in the count dictionary are\n",
      "     |  preserved.\n",
      "     |  \n",
      "     |  >>> vocab['b']\n",
      "     |  1\n",
      "     |  >>> 'b' in vocab\n",
      "     |  False\n",
      "     |  >>> vocab['aliens']\n",
      "     |  0\n",
      "     |  >>> 'aliens' in vocab\n",
      "     |  False\n",
      "     |  \n",
      "     |  Keeping the count entries for seen words allows us to change the cutoff value\n",
      "     |  without having to recalculate the counts.\n",
      "     |  \n",
      "     |  >>> vocab2 = Vocabulary(vocab.counts, unk_cutoff=1)\n",
      "     |  >>> \"b\" in vocab2\n",
      "     |  True\n",
      "     |  \n",
      "     |  The cutoff value influences not only membership checking but also the result of\n",
      "     |  getting the size of the vocabulary using the built-in `len`.\n",
      "     |  Note that while the number of keys in the vocabulary's counter stays the same,\n",
      "     |  the items in the vocabulary differ depending on the cutoff.\n",
      "     |  We use `sorted` to demonstrate because it keeps the order consistent.\n",
      "     |  \n",
      "     |  >>> sorted(vocab2.counts)\n",
      "     |  ['-', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab2)\n",
      "     |  ['-', '<UNK>', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab.counts)\n",
      "     |  ['-', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab)\n",
      "     |  ['<UNK>', 'a', 'c', 'd']\n",
      "     |  \n",
      "     |  In addition to items it gets populated with, the vocabulary stores a special\n",
      "     |  token that stands in for so-called \"unknown\" items. By default it's \"<UNK>\".\n",
      "     |  \n",
      "     |  >>> \"<UNK>\" in vocab\n",
      "     |  True\n",
      "     |  \n",
      "     |  We can look up words in a vocabulary using its `lookup` method.\n",
      "     |  \"Unseen\" words (with counts less than cutoff) are looked up as the unknown label.\n",
      "     |  If given one word (a string) as an input, this method will return a string.\n",
      "     |  \n",
      "     |  >>> vocab.lookup(\"a\")\n",
      "     |  'a'\n",
      "     |  >>> vocab.lookup(\"aliens\")\n",
      "     |  '<UNK>'\n",
      "     |  \n",
      "     |  If given a sequence, it will return an tuple of the looked up words.\n",
      "     |  \n",
      "     |  >>> vocab.lookup([\"p\", 'a', 'r', 'd', 'b', 'c'])\n",
      "     |  ('<UNK>', 'a', '<UNK>', 'd', '<UNK>', 'c')\n",
      "     |  \n",
      "     |  It's possible to update the counts after the vocabulary has been created.\n",
      "     |  The interface follows that of `collections.Counter`.\n",
      "     |  \n",
      "     |  >>> vocab['b']\n",
      "     |  1\n",
      "     |  >>> vocab.update([\"b\", \"b\", \"c\"])\n",
      "     |  >>> vocab['b']\n",
      "     |  3\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |      Only consider items with counts GE to cutoff as being in the\n",
      "     |      vocabulary.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |  \n",
      "     |  __init__(self, counts=None, unk_cutoff=1, unk_label='<UNK>')\n",
      "     |      Create a new Vocabulary.\n",
      "     |      \n",
      "     |      :param counts: Optional iterable or `collections.Counter` instance to\n",
      "     |                     pre-seed the Vocabulary. In case it is iterable, counts\n",
      "     |                     are calculated.\n",
      "     |      :param int unk_cutoff: Words that occur less frequently than this value\n",
      "     |                             are not considered part of the vocabulary.\n",
      "     |      :param unk_label: Label for marking words not part of vocabulary.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Building on membership check define how to iterate over\n",
      "     |      vocabulary.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Computing size of vocabulary reflects the cutoff.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  lookup(self, words)\n",
      "     |      Look up one or more words in the vocabulary.\n",
      "     |      \n",
      "     |      If passed one word as a string will return that word or `self.unk_label`.\n",
      "     |      Otherwise will assume it was passed a sequence of words, will try to look\n",
      "     |      each of them up and return an iterator over the looked up words.\n",
      "     |      \n",
      "     |      :param words: Word(s) to look up.\n",
      "     |      :type words: Iterable(str) or str\n",
      "     |      :rtype: generator(str) or str\n",
      "     |      :raises: TypeError for types other than strings or iterables\n",
      "     |      \n",
      "     |      >>> from nltk.lm import Vocabulary\n",
      "     |      >>> vocab = Vocabulary([\"a\", \"b\", \"c\", \"a\", \"b\"], unk_cutoff=2)\n",
      "     |      >>> vocab.lookup(\"a\")\n",
      "     |      'a'\n",
      "     |      >>> vocab.lookup(\"aliens\")\n",
      "     |      '<UNK>'\n",
      "     |      >>> vocab.lookup([\"a\", \"b\", \"c\", [\"x\", \"b\"]])\n",
      "     |      ('a', 'b', '<UNK>', ('<UNK>', 'b'))\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  update(self, *counter_args, **counter_kwargs)\n",
      "     |      Update vocabulary counts.\n",
      "     |      \n",
      "     |      Wraps `collections.Counter.update` method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  cutoff\n",
      "     |      Cutoff value.\n",
      "     |      \n",
      "     |      Items with count below this value are not considered part of vocabulary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class WittenBellInterpolated(InterpolatedLanguageModel)\n",
      "     |  WittenBellInterpolated(order, **kwargs)\n",
      "     |  \n",
      "     |  Interpolated version of Witten-Bell smoothing.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WittenBellInterpolated\n",
      "     |      InterpolatedLanguageModel\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, order, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from InterpolatedLanguageModel:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Score a word given some optional context.\n",
      "     |      \n",
      "     |      Concrete models are expected to provide an implementation.\n",
      "     |      Note that this method does not mask its arguments with the OOV label.\n",
      "     |      Use the `score` method for that.\n",
      "     |      \n",
      "     |      :param str word: Word for which we want the score\n",
      "     |      :param tuple(str) context: Context the word is in.\n",
      "     |      If `None`, compute unigram score.\n",
      "     |      :param context: tuple(str) or None\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Vocabulary', 'NgramCounter', 'MLE', 'Lidstone', 'Laplace',...\n",
      "\n",
      "FILE\n",
      "    /Users/captsolo/Documents/Code/virtual-env/py37-bigdata/lib/python3.7/site-packages/nltk/lm/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate() builds a [trigram] language model from the supplied text.\n",
    "#  - words are generated based on previous two words \n",
    "\n",
    "# For more information see nltk.lm:\n",
    "# https://www.nltk.org/api/nltk.lm.html\n",
    "\n",
    "help(nltk.lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"799\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dispersion plot\n",
    "\n",
    "# source: Inaugural Address Corpus\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"duty\", \"freedom\", \"America\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
